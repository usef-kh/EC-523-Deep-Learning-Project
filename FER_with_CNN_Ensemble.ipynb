{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER with CNN Ensemble.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOt5y+KVWFn2GJlfVSf8mPf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usef-kh/EC523-Deep-Learning-Project/blob/master/FER_with_CNN_Ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnO2nvqpALPj"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cWGQl78U9wy",
        "outputId": "5e1a19cb-8eaf-47d1-c079-3072fdca7c99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone \"https://github.com/usef-kh/EC523-Deep-Learning-Project.git\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'EC523-Deep-Learning-Project'...\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 21 (delta 4), reused 3 (delta 0), pack-reused 8\u001b[K\n",
            "Unpacking objects: 100% (21/21), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgKnn2ux6Pgp",
        "outputId": "b866e577-4345-44fe-c175-112c15faa894",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install unrar"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unrar\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/0b/53130ccd483e3db8c8a460cb579bdb21b458d5494d67a261e1a5b273fbb9/unrar-0.4-py3-none-any.whl\n",
            "Installing collected packages: unrar\n",
            "Successfully installed unrar-0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtrv6tM-Xq2n",
        "outputId": "ffb8fcb2-a7eb-4d81-8c71-2d0ef7a0364d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# !unrar x \"EC523-Deep-Learning-Project/datasets/ckplus.rar\"\n",
        "!unrar e \"EC523-Deep-Learning-Project/datasets/fer2013.rar\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from EC523-Deep-Learning-Project/datasets/fer2013.rar\n",
            "\n",
            "Extracting  fer2013.csv                                                  \b\b\b\b  4%\b\b\b\b  9%\b\b\b\b 13%\b\b\b\b 18%\b\b\b\b 23%\b\b\b\b 27%\b\b\b\b 32%\b\b\b\b 37%\b\b\b\b 41%\b\b\b\b 46%\b\b\b\b 51%\b\b\b\b 55%\b\b\b\b 60%\b\b\b\b 65%\b\b\b\b 69%\b\b\b\b 74%\b\b\b\b 79%\b\b\b\b 83%\b\b\b\b 88%\b\b\b\b 93%\b\b\b\b 97%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rN_6jQNFAH8t"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ-kmOyAAHLn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import optim\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBi_q71MAOLY"
      },
      "source": [
        "##Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYuiGVdr_3PF",
        "outputId": "6cc54001-7a95-44c5-cd03-3c85d0138f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "fer2013 = pd.read_csv('fer2013.csv') \n",
        "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
        "fer2013.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion                                             pixels     Usage\n",
              "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
              "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
              "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
              "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
              "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F54zA1oAASTM"
      },
      "source": [
        "def prepare_data(data):\n",
        "    \"\"\" Prepare data for modeling \n",
        "        input: data frame with labels und pixel data\n",
        "        output: image and label array \"\"\"\n",
        "    \n",
        "    image_array = np.zeros(shape=(len(data), 48, 48))\n",
        "    image_label = np.array(list(map(int, data['emotion'])))\n",
        "    \n",
        "    for i, row in enumerate(data.index):\n",
        "        image = np.fromstring(data.loc[row, 'pixels'], dtype=int, sep=' ')\n",
        "        image = np.reshape(image, (48, 48))\n",
        "        image_array[i] = image\n",
        "        \n",
        "    return image_array, image_label\n",
        "\n",
        "\n",
        "def reformat_data(X, Y):\n",
        "    data = []\n",
        "\n",
        "    for x, y in zip(torch.from_numpy(X), torch.from_numpy(Y)):\n",
        "        x, y = x.type(torch.DoubleTensor), y.type(torch.long)\n",
        "        data.append((x.unsqueeze(0), y))\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "xtrain, ytrain = prepare_data(fer2013[fer2013['Usage'] == 'Training'])\n",
        "xval , yval = prepare_data(fer2013[fer2013['Usage'] == 'PrivateTest'])\n",
        "xtest, ytest = prepare_data(fer2013[fer2013['Usage'] == 'PublicTest'])\n",
        "\n",
        "train = reformat_data(xtrain, ytrain)\n",
        "val = reformat_data(xval, yval)\n",
        "test = reformat_data(xtest, ytest)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train, batch_size=100, shuffle=True, num_workers=2)\n",
        "valloader = torch.utils.data.DataLoader(val, batch_size=100, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(test, batch_size=100, shuffle=True, num_workers=2)\n",
        "\n",
        "del train, test, val, xtrain, ytrain, xval, yval, xtest, ytest, fer2013"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lv4xMhpGOBu",
        "outputId": "d66bdefe-f0b3-4774-c9f0-b103849f7067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# # get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "print(labels.shape)\n",
        "\n",
        "# print(images.shape)\n",
        "# img = images[0]\n",
        "# print(img.shape)\n",
        "# plt.imshow(img.numpy())\n",
        "# print(emotions[labels[0].item()])\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIEFhmKoCyZ1"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV0nfy_5CzwG"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Subnet1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Subnet1, self).__init__()\n",
        "        # Not sure about number of in channels, may have to change!\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1) # according to paper!\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "        self.conv2 = nn.Conv2d(64,128,3,padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "\n",
        "        self.lin1 = nn.Linear(128 * 10 * 10, 4096) # Will have to change input size\n",
        "        self.lin2 = nn.Linear(4096, 4096)\n",
        "        self.lin3 = nn.Linear(4096, 7)\n",
        "\n",
        "        #self.drop = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = F.relu(self.conv1(x))\n",
        "        #print(\"shape after 1 conv layer: \", x.shape)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        #print(\"shape after 2 conv layer: \", x.shape)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        #print(\"shape after 3 conv layer: \", x.shape)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        #print(\"shape before linear layers!!: \", x.shape)\n",
        "\n",
        "        x = x.view(x.size(0), 128*10*10) # will have to change!\n",
        "\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = self.lin3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "sub1 = Subnet1()\n",
        "\n",
        "\n",
        "#####################################\n",
        "\n",
        "# define nets for CNN emotion detection problem\n",
        "\n",
        "class Subnet2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Subnet2, self).__init__()\n",
        "        # Not sure about number of in channels, may have to change!\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1) # according to paper!\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "        self.conv2 = nn.Conv2d(64,128,3,padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.conv3_2 = nn.Conv2d(256,256, 3, padding=1)\n",
        "        self.lin1 = nn.Linear(128 * 10 * 10, 4096) # MUST CHANGE\n",
        "        self.lin2 = nn.Linear(4096, 4096)\n",
        "        self.lin3 = nn.Linear(4096, 7)\n",
        "\n",
        "        #self.drop = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = F.relu(self.conv1(x))\n",
        "        #print(\"shape after 1 conv layer: \", x.shape)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        #print(\"shape after 2 conv layer: \", x.shape)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv3_2(x))\n",
        "        #print(\"shape after 3 conv layer: \", x.shape)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = x.view(x.size(0), 128*10*10)\n",
        "\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = self.lin3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "sub2 = Subnet2()\n",
        "\n",
        "# define nets for CNN emotion detection problem\n",
        "\n",
        "class Subnet3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Subnet3, self).__init__()\n",
        "        # Not sure about number of in channels, may have to change!\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1) # according to paper!\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "        self.conv2 = nn.Conv2d(64,128,3,padding=1)\n",
        "        self.conv2_2 = nn.Conv2d(128,128,3,padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.conv3_2 = nn.Conv2d(256,256, 3, padding=1)\n",
        "        self.lin1 = nn.Linear(128 * 10 * 10, 4096) # MUST CHANGE\n",
        "        self.lin2 = nn.Linear(4096, 4096)\n",
        "        self.lin3 = nn.Linear(4096, 7)\n",
        "\n",
        "        #self.drop = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = F.relu(self.conv1(x))\n",
        "        #print(\"shape after 1 conv layer: \", x.shape)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv2_2(x))\n",
        "        #print(\"shape after 2 conv layer: \", x.shape)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv3_2(x))\n",
        "        #print(\"shape after 3 conv layer: \", x.shape)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = x.view(x.size(0), 128*10*10) # CHANGE\n",
        "\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = self.lin3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "sub3 = Subnet3()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCuMQu5bF5nE"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmVUpKgfDIYt"
      },
      "source": [
        "class Subnet1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Subnet1, self).__init__()\n",
        "        # Not sure about number of in channels, may have to change!\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1) # according to paper!\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "        self.conv2 = nn.Conv2d(64,128,3,padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "\n",
        "        self.lin1 = nn.Linear(256*6*6, 4096) # Will have to change input size\n",
        "        self.lin2 = nn.Linear(4096, 4096)\n",
        "        self.lin3 = nn.Linear(4096, 7)\n",
        "        \n",
        "        #self.drop = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        #print(\"shape after 1 conv layer: \", x.shape)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        #print(\"shape after 2 conv layer: \", x.shape)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        #print(\"shape after 3 conv layer: \", x.shape)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # print(\"shape before linear layers!!: \", x.shape)\n",
        "\n",
        "        x = x.view(-1, 256*6*6) # will have to change!\n",
        "        # print(\"reshaped\", x.shape)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = self.lin3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "sub1 = Subnet1()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wME97MptDeex",
        "outputId": "7ba20460-f611-4849-85a1-de9032e80b6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "net = Subnet1()\n",
        "net = net.to(device)\n",
        "net.double()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Subnet1(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (lin1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "  (lin2): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (lin3): Linear(in_features=4096, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACcirLVUPzUd"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3asDIi_yDQLW"
      },
      "source": [
        "def train_model(net, trainloader, valloader):\n",
        "\n",
        "    train_loss = []\n",
        "    val_loss = []\n",
        "    num = 100\n",
        "    for epoch in range(5):\n",
        "        print(\"Training\")\n",
        "        net = net.train()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            \n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % num == num - 1 :    \n",
        "                print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / num))\n",
        "                train_loss.append(running_loss / num)\n",
        "                running_loss = 0.0\n",
        "        \n",
        "        print(\"Validating\")\n",
        "        net = net.eval()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(valloader):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % num == num - 1:    \n",
        "                print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / num))\n",
        "                val_loss.append(running_loss / num)\n",
        "                running_loss = 0.0\n",
        "\n",
        "    return train_loss, val_loss"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9npmfIq5FgZ1",
        "outputId": "28d0e52e-8f6e-41e3-a6e1-b1cbd3d16321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "train_loss, val_loss = train_model(net, trainloader, valloader)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-d4009bbc71cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-45-ceed1b26a256>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(net, trainloader, valloader)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() takes 2 positional arguments but 3 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaGNnlXTJdeG"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(train_loss)\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(val_loss)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}