{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPwTGLLVlU9sojKCakf5KTh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usef-kh/EC523-Deep-Learning-Project/blob/master/FER_with_CNN_Ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnO2nvqpALPj"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cWGQl78U9wy",
        "outputId": "2d8ac454-0232-44f0-8e9c-2c5641cd988e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone \"https://github.com/usef-kh/EC523-Deep-Learning-Project.git\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'EC523-Deep-Learning-Project'...\n",
            "remote: Enumerating objects: 32, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 40 (delta 14), reused 14 (delta 4), pack-reused 8\u001b[K\n",
            "Unpacking objects: 100% (40/40), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgKnn2ux6Pgp",
        "outputId": "8016d6e2-2e6e-4707-e403-9fca82549e7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!pip install unrar"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unrar\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/0b/53130ccd483e3db8c8a460cb579bdb21b458d5494d67a261e1a5b273fbb9/unrar-0.4-py3-none-any.whl\n",
            "Installing collected packages: unrar\n",
            "Successfully installed unrar-0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtrv6tM-Xq2n",
        "outputId": "5cb45d87-a91a-4f8e-dc01-096520b2357e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# !unrar x \"EC523-Deep-Learning-Project/datasets/ckplus.rar\"\n",
        "!unrar e \"EC523-Deep-Learning-Project/datasets/fer2013_processed.rar\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from EC523-Deep-Learning-Project/datasets/fer2013_processed.rar\n",
            "\n",
            "Extracting  val                                                          \b\b\b\b  4%\b\b\b\b  8%\b\b\b\b 10%\b\b\b\b\b  OK \n",
            "Extracting  test                                                         \b\b\b\b 14%\b\b\b\b 18%\b\b\b\b 20%\b\b\b\b\b  OK \n",
            "Extracting  train                                                        \b\b\b\b 24%\b\b\b\b 28%\b\b\b\b 33%\b\b\b\b 37%\b\b\b\b 42%\b\b\b\b 46%\b\b\b\b 50%\b\b\b\b 55%\b\b\b\b 59%\b\b\b\b 64%\b\b\b\b 68%\b\b\b\b 73%\b\b\b\b 77%\b\b\b\b 81%\b\b\b\b 86%\b\b\b\b 90%\b\b\b\b 95%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rN_6jQNFAH8t"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ-kmOyAAHLn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBi_q71MAOLY"
      },
      "source": [
        "##Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F54zA1oAASTM"
      },
      "source": [
        "train = torch.load(\"train\")\n",
        "val = torch.load(\"val\")\n",
        "test = torch.load(\"test\")\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train, batch_size=100, shuffle=True, num_workers=2)\n",
        "valloader = torch.utils.data.DataLoader(val, batch_size=100, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(test, batch_size=100, shuffle=True, num_workers=2)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lv4xMhpGOBu",
        "outputId": "fefdb647-964f-421e-a1fa-e4913227ce84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "print(images.shape, labels.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 1, 48, 48]) torch.Size([100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIEFhmKoCyZ1"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV0nfy_5CzwG"
      },
      "source": [
        "class Subnet1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Subnet1, self).__init__()\n",
        "        # Not sure about number of in channels, may have to change!\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1) # according to paper!\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "        self.conv2 = nn.Conv2d(64,128,3,padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "\n",
        "        self.lin1 = nn.Linear(256*6*6, 4096) # Will have to change input size\n",
        "        self.lin2 = nn.Linear(4096, 4096)\n",
        "        self.lin3 = nn.Linear(4096, 7)\n",
        "        \n",
        "        #self.drop = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        #print(\"shape after 1 conv layer: \", x.shape)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        #print(\"shape after 2 conv layer: \", x.shape)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        #print(\"shape after 3 conv layer: \", x.shape)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # print(\"shape before linear layers!!: \", x.shape)\n",
        "\n",
        "        x = x.view(-1, 256*6*6) # will have to change!\n",
        "        # print(\"reshaped\", x.shape)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = self.lin3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "sub1 = Subnet1()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCuMQu5bF5nE"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wME97MptDeex",
        "outputId": "c1f17e10-729e-4f5e-86ca-418070424412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "net = Subnet1()\n",
        "net = net.to(device)\n",
        "net.double()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Subnet1(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (lin1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "  (lin2): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (lin3): Linear(in_features=4096, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACcirLVUPzUd"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3asDIi_yDQLW"
      },
      "source": [
        "def train_model(net, trainloader, valloader):\n",
        "\n",
        "    train_loss = []\n",
        "    val_loss = []\n",
        "    num = 10\n",
        "    for epoch in range(20):\n",
        "        print(\"Training\")\n",
        "        net = net.train()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            \n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % num == num - 1 :    \n",
        "                print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / num))\n",
        "                train_loss.append(running_loss / num)\n",
        "                running_loss = 0.0\n",
        "        \n",
        "        print(\"Validating\")\n",
        "        net = net.eval()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(valloader):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % num == num - 1:    \n",
        "                print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / num))\n",
        "                val_loss.append(running_loss / num)\n",
        "                running_loss = 0.0\n",
        "\n",
        "    return train_loss, val_loss"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9npmfIq5FgZ1",
        "outputId": "a3a74814-afa1-44e7-e33c-a612ff376a34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "train_loss, val_loss = train_model(net, trainloader, valloader)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-d4009bbc71cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-d126edc3f834>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(net, trainloader, valloader)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaGNnlXTJdeG"
      },
      "source": [
        "fig, ax = plt.subplots()  # Create a figure and an axes.\n",
        "ax.plot(train_loss, 'b')  # ... and some more.\n",
        "ax.set_xlabel('Iteration(batch)')  # Add an x-label to the axes.\n",
        "ax.set_ylabel('Training Loss')  # Add a y-label to the axes.\n",
        "ax.set_title(\"Loss vs. Iteration\")  # Add a title to the axes.\n",
        "\n",
        "fig, ax = plt.subplots()  # Create a figure and an axes.\n",
        "ax.plot(val_loss, 'r')  # ... and some more.\n",
        "ax.set_xlabel('Iteration(batch)')  # Add an x-label to the axes.\n",
        "ax.set_ylabel('Validation Loss')  # Add a y-label to the axes.\n",
        "ax.set_title(\"Loss vs. Iteration\")  # Add a title to the axes.\n",
        "\n",
        "\n",
        "# plt.plot(train_loss)\n",
        "# plt.plot(val_loss)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}